{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JFrois/Envio_de_casos/blob/main/Envio_de_casos.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pe9r6icxlKJb"
      },
      "source": [
        "# 1. Instalações necessárias\n",
        "\n",
        "* Pips install para conseguir realizar os imports\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_bKsHVfvlIcs"
      },
      "outputs": [],
      "source": [
        "!pip install pandas gspread openpyxl gspread_dataframe xlsxwriter\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jOUb9bf74FOQ"
      },
      "source": [
        "# 2. Imports das bibliotecas\n",
        "\n",
        "* Imports necessários para autenticação, pandas, datetime, google sheets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lMzePt6k4IQQ"
      },
      "outputs": [],
      "source": [
        "import gspread\n",
        "import pandas as pd\n",
        "import time\n",
        "from google.colab import auth, drive\n",
        "from google.auth import default\n",
        "import os\n",
        "from datetime import datetime\n",
        "import re"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m56RZ987h8OV"
      },
      "source": [
        "# 3. Código para consolidação das planilhas de ITBI\n",
        "\n",
        "\n",
        "\n",
        "* Período: 2019 a 2025\n",
        "* Filtra por tipo transação = Compra e venda\n",
        "* Exclui colunas que não fazem sentido ter:\n",
        "Referência\n",
        "Valor de Transação (declarado pelo contribuinte)\n",
        "Valor Venal de Referência\n",
        "Proporção Transmitida (%)\n",
        "Valor Venal de Referência (Proporcional)\n",
        "Base de Cálculo adotada\n",
        "Tipo de Financiamento\n",
        "Valor Financiado\n",
        "Situação SQL\n",
        "Área do Terreno (m2)\n",
        "Testada (m)\n",
        "Fração Ideal\n",
        "Área Construída (m2)\n",
        "Uso (IPTU)\n",
        "Descrição do uso (IPTU)\n",
        "Padrão (IPTU)\n",
        "ACC (IPTU)\n",
        "ACC (IPTU).1\n",
        "escrição do padrão (IPTU)\n",
        "Unnamed:28"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sIYyUya0h9OE"
      },
      "outputs": [],
      "source": [
        "# Lista os Drives disponíveis\n",
        "shared_drives_path = \"informe seu drive\"\n",
        "#print(\"Drives disponíveis:\")\n",
        "#print(os.listdir(shared_drives_path))\n",
        "\n",
        "\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# Autenticação para acessar o Google Drive e Google Sheets\n",
        "auth.authenticate_user()\n",
        "creds, _ = default()\n",
        "gc = gspread.authorize(creds)\n",
        "\n",
        "\n",
        "# Caminho da pasta onde estão os arquivos Excel\n",
        "data_file_folder = os.path.join('Informe caminho da pasta')\n",
        "\n",
        "\n",
        "# Define os arquivos e abas correspondentes\n",
        "file_paths = [\n",
        "    os.path.join(data_file_folder, 'GUIAS DE ITBI PAGAS (2019).xlsx'),\n",
        "    os.path.join(data_file_folder, 'GUIAS DE ITBI PAGAS (2020).xlsx'),\n",
        "    os.path.join(data_file_folder, 'GUIAS DE ITBI PAGAS (2021).xlsx'),\n",
        "    os.path.join(data_file_folder, 'GUIAS DE ITBI PAGAS (2022).xlsx'),\n",
        "    os.path.join(data_file_folder, 'GUIAS DE ITBI PAGAS (2023).xlsx'),\n",
        "    os.path.join(data_file_folder, 'GUIAS DE ITBI PAGAS (2024).xlsx'),\n",
        "    os.path.join(data_file_folder, 'GUIAS DE ITBI PAGAS (2025).xlsx'),\n",
        "]\n",
        "\n",
        "# Definindo as abas por ano\n",
        "sheet_names = {\n",
        "    2019: ['JAN-2019', 'FEV-2019', 'MAR-2019', 'ABR-2019', 'MAI-2019', 'JUN-2019', 'JUL-2019',\n",
        "           'AGO-2019', 'SET-2019', 'OUT-2019', 'NOV-2019', 'DEZ-2019'],\n",
        "    2020: ['JAN-2020', 'FEV-2020', 'MAR-2020', 'ABR-2020', 'MAI-2020', 'JUN-2020', 'JUL-2020',\n",
        "           'AGO-2020', 'SET-2020', 'OUT-2020', 'NOV-2020', 'DEZ-2020'],\n",
        "    2021: ['JAN-2021', 'FEV-2021', 'MAR-2021', 'ABR-2021', 'MAI-2021', 'JUN-2021', 'JUL-2021',\n",
        "           'AGO-2021', 'SET-2021', 'OUT-2021', 'NOV-2021', 'DEZ-2021'],\n",
        "    2022: ['JAN-2022', 'FEV-2022', 'MAR-2022', 'ABR-2022', 'MAI-2022', 'JUN-2022', 'JUL-2022',\n",
        "           'AGO-2022', 'SET-2022', 'OUT-2022', 'NOV-2022', 'DEZ-2022'],\n",
        "    2023: ['JAN-2023', 'FEV-2023', 'MAR-2023', 'ABR-2023', 'MAI-2023', 'JUN-2023', 'JUL-2023',\n",
        "           'AGO-2023', 'SET-2023', 'OUT-2023', 'NOV-2023', 'DEZ-2023'],\n",
        "    2024: ['JAN-2024', 'FEV-2024', 'MAR-2024', 'ABR-2024', 'MAI-2024', 'JUN-2024', 'JUL-2024',\n",
        "           'AGO-2024', 'SET-2024', 'OUT-2024', 'NOV-2024','DEZ-2024'],\n",
        "    2025: ['JAN-2025', 'FEV-2025','MAR-2025'],\n",
        "}\n",
        "\n",
        "# Variável para armazenar os dados consolidados\n",
        "history_data = pd.DataFrame()\n",
        "\n",
        "# Loop para consolidar dados de todas as abas de todas as planilhas\n",
        "for file_path, year in zip(file_paths, sheet_names.keys()):\n",
        "    for sheet_name in sheet_names[year]:\n",
        "        try:\n",
        "            table = pd.read_excel(file_path, sheet_name=sheet_name)\n",
        "            table.columns = table.columns.str.strip()\n",
        "\n",
        "            if 'Natureza de Transação' not in table.columns:\n",
        "                print(f\"Pulando {sheet_name} de {file_path} - Coluna 'Natureza de Transação' não encontrada\")\n",
        "                continue\n",
        "\n",
        "            history_data = pd.concat([history_data, table], axis=0, ignore_index=True)\n",
        "            print(f\"Carregado: {sheet_name} de {file_path}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Erro ao carregar {sheet_name} de {file_path}: {e}\")\n",
        "\n",
        "\n",
        "# Remoção das colunas desnecessárias\n",
        "columns_to_remove = [\n",
        "    'Referência', 'Valor de Transação (declarado pelo contribuinte)', 'Valor Venal de Referência',\n",
        "    'Proporção Transmitida (%)', 'Valor Venal de Referência (Proporcional)', 'Base de Cálculo adotada',\n",
        "    'Tipo de Financiamento', 'Valor Financiado', 'Situação SQL', 'Área do Terreno (m2)', 'Testada (m)',\n",
        "    'Fração Ideal', 'Área Construída (m2)', 'Uso (IPTU)', 'Descrição do uso (IPTU)', 'Padrão (IPTU)',\n",
        "    'ACC (IPTU)', 'ACC (IPTU).1', 'escrição do padrão (IPTU)', 'Unnamed:28'\n",
        "    ]\n",
        "\n",
        "history_data = history_data.drop(columns=columns_to_remove, errors='ignore')\n",
        "\n",
        "# Filtra os dados pela coluna \"Natureza de Transação\"\n",
        "filtered_data = history_data[history_data['Natureza de Transação'] == '1.Compra e venda']\n",
        "\n",
        "# Padroniza a coluna \"Data de Transação\"\n",
        "filtered_data['Data de Transação'] = pd.to_datetime(filtered_data['Data de Transação'], format='%d/%m/%Y', errors='coerce')\n",
        "\n",
        "# Padroniza a coluna \"Cartório de Registro\"\n",
        "filtered_data['Cartório de Registro'] = filtered_data['Cartório de Registro'].str.replace('CARTORIO DE REGISTRO DE IMOVEL', '', regex=False).str.strip()\n",
        "\n",
        "# Padroniza a coluna \"Cartório de Registro\"\n",
        "filtered_data['Cartório de Registro'] = filtered_data['Cartório de Registro'].str.replace('º Cartório de Registro de Imóvel', '', regex=False).str.strip()\n",
        "\n",
        "# Salva os dados consolidados em um novo arquivo Excel\n",
        "output_file = os.path.join(data_file_folder, 'ITBI SP CONSOLIDADO(2019 - 2025).xlsx')\n",
        "filtered_data.to_excel(output_file, index=False)\n",
        "\n",
        "print(f\"Consolidação concluída. Arquivo salvo em: {output_file}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PMQTsftvVraS"
      },
      "source": [
        "# 4. Quais casos de SP com número de matricula tivemos movimentação\n",
        "\n",
        "*   Neste código é realizado a verificação de quais casos tivemos movimentação de ITBI de SP\n",
        "\n",
        "**Como é feito a verificação:**\n",
        "\n",
        "* **Informações necessárias:** Data primeira visita e número de matricula\n",
        "\n",
        "\n",
        "1.   Verifica se o número de matricula do imóvel que consta na nossa base é igual planilha de ITBI\n",
        "2.   Se a verificação acima for verdadeira, o códio faz a verificação da data de primeira visita e caso a data da transação for igual ou maior que a data da primeira visita consta como motivmentação = Sim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hcJTYyOBWDJc"
      },
      "outputs": [],
      "source": [
        "shared_drives_path = \"/content/drive/Shareddrives\"\n",
        "\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# Autenticação para acessar o Google Drive e Google Sheets\n",
        "auth.authenticate_user()\n",
        "creds, _ = default()\n",
        "gc = gspread.authorize(creds)\n",
        "\n",
        "# Caminho do arquivo Excel no Google Drive\n",
        "itbi_excel_path = 'Informe caminho da pasta'\n",
        "\n",
        "# Carregar os dados do ITBI (Excel)\n",
        "itbi_data = pd.read_excel(itbi_excel_path)\n",
        "\n",
        "# Abrir a planilha Google Sheets de CasosSP\n",
        "casos_sp_sheet = gc.open('Verificação casos para envio')  # Nome da planilha\n",
        "casos_sp_aba = casos_sp_sheet.worksheet('CasosSP - Com matricula')  # Nome da aba\n",
        "casos_data = pd.DataFrame(casos_sp_aba.get_all_records())\n",
        "\n",
        "# Mapeamento de meses por extenso para números\n",
        "meses_map = {\n",
        "    \"janeiro\": \"01\", \"fevereiro\": \"02\", \"março\": \"03\", \"abril\": \"04\", \"maio\": \"05\",\n",
        "    \"junho\": \"06\", \"julho\": \"07\", \"agosto\": \"08\", \"setembro\": \"09\", \"outubro\": \"10\",\n",
        "    \"novembro\": \"11\", \"dezembro\": \"12\"\n",
        "}\n",
        "\n",
        "# Função para substituir meses por extenso por números\n",
        "def substituir_meses(data_str):\n",
        "    if not isinstance(data_str, str):\n",
        "        return data_str\n",
        "    for mes, num in meses_map.items():\n",
        "        data_str = re.sub(rf'\\b{mes}\\b', num, data_str, flags=re.IGNORECASE)\n",
        "    return data_str\n",
        "\n",
        "# Atualizar a coluna de datas na planilha CasosSP\n",
        "if 'primeira_visita' in casos_data.columns:\n",
        "    casos_data['primeira_visita'] = (\n",
        "        casos_data['primeira_visita']\n",
        "        .apply(substituir_meses)\n",
        "        .apply(lambda x: pd.to_datetime(x, errors='coerce').strftime('%d/%m/%Y') if pd.to_datetime(x, errors='coerce') else None)\n",
        "    )\n",
        "\n",
        "# Padronizar datas na planilha ITBI\n",
        "itbi_data['Data de Transação'] = itbi_data['Data de Transação'].apply(\n",
        "    lambda x: pd.to_datetime(x, errors='coerce').strftime('%d/%m/%Y') if pd.to_datetime(x, errors='coerce') else None\n",
        ")\n",
        "\n",
        "# Adicionar colunas para os resultados, caso não existam\n",
        "if 'Movimentação' not in casos_data.columns:\n",
        "    casos_data['Movimentação'] = 'Não'\n",
        "if 'Data de Movimentação' not in casos_data.columns:\n",
        "    casos_data['Data de Movimentação'] = None\n",
        "\n",
        "# Processar os dados\n",
        "for idx, caso in casos_data.iterrows():\n",
        "    # Obter informações do caso\n",
        "    primeira_visita = pd.to_datetime(caso['primeira_visita'], format='%d/%m/%Y', errors='coerce')\n",
        "    matricula_caso = caso.get('numero_matricula')\n",
        "\n",
        "    if pd.isna(primeira_visita) or not matricula_caso:\n",
        "        continue  # Ignorar linhas com dados insuficientes\n",
        "\n",
        "    # Filtrar as movimentações do ITBI\n",
        "    movimentacao = itbi_data[\n",
        "        (pd.to_datetime(itbi_data['Data de Transação'], format='%d/%m/%Y', errors='coerce') >= primeira_visita) &\n",
        "        (itbi_data['Matrícula do Imóvel'] == matricula_caso)\n",
        "    ]\n",
        "\n",
        "    # Se encontrar movimentação, atualize os resultados\n",
        "    if not movimentacao.empty:\n",
        "        casos_data.at[idx, 'Movimentação'] = 'Sim'\n",
        "        casos_data.at[idx, 'Data de Movimentação'] = movimentacao['Data de Transação'].iloc[0]\n",
        "\n",
        "# Garantir que as colunas de data estão formatadas como string no padrão esperado\n",
        "casos_data['primeira_visita'] = casos_data['primeira_visita'].fillna('').astype(str)\n",
        "casos_data['Data de Movimentação'] = casos_data['Data de Movimentação'].fillna('').astype(str)\n",
        "\n",
        "# Atualizar os valores na planilha Google Sheets\n",
        "casos_sp_aba.update([casos_data.columns.values.tolist()] + casos_data.values.tolist())\n",
        "\n",
        "print(\"Planilha de CasosSP atualizada com sucesso!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XtjD9LcSwT9Y"
      },
      "source": [
        "# 5. Envio de casos para API\n",
        "\n",
        "\n",
        "\n",
        "*   Neste código, é enviado os casos da planilha de estudo para a nossa API da Zendesk\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LJFTANNbwej4"
      },
      "outputs": [],
      "source": [
        "# Caminho completo do arquivo de controle\n",
        "#caminho_arquivo = r\"C:\\Users\\juan.frois\\Desktop\\Python\\API planilha estudo\\ultimo_caso.txt\"\n",
        "\n",
        "shared_drives_path = \"/content/drive/Shareddrives\"\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "caminho_arquivo = 'Informe caminho da pasta'\n",
        "\n",
        "# Autenticação e acesso às planilhas\n",
        "auth.authenticate_user()\n",
        "creds, _ = default()\n",
        "gc = gspread.authorize(creds)\n",
        "\n",
        "# Acesso às planilhas\n",
        "planilha = gc.open(\"Estudo Bypass\")\n",
        "aba_backlog = planilha.worksheet(\"Enviar para API\")\n",
        "\n",
        "planilhaApi = gc.open(\"Estudo Bypass\")\n",
        "aba_api = planilhaApi.worksheet(\"Enviado para API\")\n",
        "\n",
        "# Carrega o índice do último caso enviado e a data do envio\n",
        "def carregar_ultimo_caso():\n",
        "    if os.path.exists(caminho_arquivo):\n",
        "        with open(caminho_arquivo, \"r\") as f:\n",
        "            linhas = f.readlines()\n",
        "            ultimo_caso = int(linhas[0].strip())\n",
        "            data_envio = linhas[1].strip() if len(linhas) > 1 else \"Data não registrada\"\n",
        "            return ultimo_caso, data_envio\n",
        "    return 0, \"Data não registrada\"  # Se o arquivo não existe, começa do caso 0\n",
        "\n",
        "# Salva o índice do último caso enviado e a data do envio\n",
        "def salvar_ultimo_caso(indice):\n",
        "    data_atual = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "    with open(caminho_arquivo, \"w\") as f:\n",
        "        f.write(f\"{indice}\\n{data_atual}\")\n",
        "\n",
        "# Função para copiar dados da \"Backlog\" para a \"API\" na mesma ordem, evitando duplicatas completas\n",
        "def copiar_dados():\n",
        "    try:\n",
        "        # Carrega os dados da aba \"Backlog\" ignorando o cabeçalho\n",
        "        backlog_lista = aba_backlog.get_all_values()[1:]  # Ignora o cabeçalho\n",
        "        backlog_df = pd.DataFrame(backlog_lista, columns=aba_backlog.row_values(1))  # DataFrame com cabeçalho\n",
        "\n",
        "        # Carrega os dados existentes da aba \"API\" ignorando o cabeçalho\n",
        "        api_lista = aba_api.get_all_values()[1:]  # Ignora o cabeçalho\n",
        "        api_df = pd.DataFrame(api_lista, columns=aba_api.row_values(1)) if api_lista else pd.DataFrame()\n",
        "\n",
        "        # Cria conjuntos com os valores da coluna A para comparação\n",
        "        backlog_coluna_a = set(backlog_df.iloc[:, 0])  # Coluna A da Backlog\n",
        "        api_coluna_a = set(api_df.iloc[:, 0]) if not api_df.empty else set()  # Coluna A da API\n",
        "\n",
        "        # Filtra apenas os casos da Backlog que não estão na API\n",
        "        backlog_nao_enviados = backlog_df[~backlog_df.iloc[:, 0].isin(api_coluna_a)]\n",
        "\n",
        "        # Verifica se há novos casos para enviar\n",
        "        if not backlog_nao_enviados.empty:\n",
        "            # Seleciona até 90 casos para enviar por vez\n",
        "            casos_para_enviar = backlog_nao_enviados.head(90).values.tolist()\n",
        "\n",
        "            # Define a última linha preenchida na aba \"API\"\n",
        "            ultima_linha_api = len(api_df) + 2  # +2 por causa do cabeçalho\n",
        "\n",
        "            # Atualiza a aba \"API\" com os novos casos\n",
        "            aba_api.update(f\"A{ultima_linha_api}\", casos_para_enviar)\n",
        "            print(f\"{len(casos_para_enviar)} novos casos foram copiados para a aba 'API'.\")\n",
        "\n",
        "            # Salva o índice do último caso enviado\n",
        "            salvar_ultimo_caso(len(backlog_df) - len(backlog_nao_enviados))\n",
        "        else:\n",
        "            print(\"Não há novos casos na aba 'Backlog' para enviar para a aba 'API'.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Ocorreu um erro ao tentar copiar os dados: {e}\")\n",
        "\n",
        "# Executa continuamente com timer de 600 segundos\n",
        "def executar_com_timer(intervalo=600):  # 600 segundos = 10 minutos\n",
        "    while True:\n",
        "        print(f\"Iniciando verificação: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "        copiar_dados()\n",
        "        print(f\"Próxima verificação em {intervalo / 60} minutos.\\n\")\n",
        "        time.sleep(intervalo)\n",
        "\n",
        "# Inicia o processo com timer de 600 segundos\n",
        "executar_com_timer(600)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "pe9r6icxlKJb",
        "jOUb9bf74FOQ",
        "m56RZ987h8OV",
        "PMQTsftvVraS",
        "XtjD9LcSwT9Y"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}